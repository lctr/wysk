use std::{iter::Peekable, str::Chars};

use wy_intern::symbol::Symbol;
use wy_span::{BytePos, Coord, Location, Position, Span, WithLoc, WithSpan};

use crate::comment::Comment;
use crate::meta::Placement;
use crate::token::{Lexeme, Token};

/// A character iterator that tracks byte position as well as row (=line) and
/// column locations.
#[derive(Clone, Debug)]
pub struct Source<'t> {
    pub(crate) src: &'t str,
    pub(crate) pos: BytePos,
    pub(crate) coord: Coord,
    chars: Peekable<Chars<'t>>,
}

impl<'t> WithLoc for Source<'t> {
    fn get_coord(&self) -> Coord {
        self.coord
    }
}

impl<'t> WithSpan for Source<'t> {
    fn get_pos(&self) -> BytePos {
        self.pos
    }
}

impl<'t> AsRef<str> for Source<'t> {
    fn as_ref(&self) -> &str {
        self.src
    }
}

impl<'t> Source<'t> {
    pub fn new(src: &'t str) -> Self {
        Self {
            src,
            chars: src.chars().peekable(),
            pos: BytePos::ZERO,
            coord: Coord::new(),
        }
    }

    /// Returns the last byte position possible. Equivalent to taking the length
    /// of the inner string slice and (casting to u32 +) wrapping the result
    /// within a `BytePos`.
    pub fn end_pos(&self) -> BytePos {
        BytePos::strlen(self.src)
    }

    pub fn get_pos(&self) -> BytePos {
        self.pos
    }

    pub fn get_coord(&self) -> Coord {
        self.coord
    }

    pub fn peek(&mut self) -> Option<&char> {
        self.chars.peek()
    }

    /// Takes the character returned -- if any -- from calling the `peek`
    /// method on the underlying character stream and updates the current byte
    /// position in the `pos` field according to the number of bytes in said
    /// character. Additionally updates the layout location, incremeenting the
    /// `row` by 1 if encountering a line-feed `\n`, and otherwise incrementing
    /// the `column` by 1. If there are no characters left, no side effects are
    /// performed and `None` is returned.
    pub fn bump(&mut self) -> Option<char> {
        if let Some(c) = self.chars.peek() {
            self.pos += if c == &'\n' {
                self.coord.incr_row()
            } else {
                self.coord.incr_column(*c)
            };
            self.chars.next()
        } else {
            None
        }
    }

    /// Given a predicate, advances the iterator. Returns a boolean indicating
    /// whether the predicate passed (and hence advanced the iterator).
    pub fn bump_on(&mut self, f: impl Character) -> bool {
        if matches!(self.peek(), Some(c) if f.cmp_char(*c)) {
            self.bump();
            true
        } else {
            false
        }
    }

    pub fn is_done(&mut self) -> bool {
        self.chars.peek().is_none()
    }

    /// Given an initial `Pos` *start*, returns the span generated from the
    /// *start* to the current `Pos`.
    pub fn span_from(&self, start: BytePos) -> Span {
        Span(start, self.get_pos())
    }

    /// Given an initial `Loc` *start*, returns the `Location` generated
    /// from the *start* to the current `Loc`.
    pub fn location_from(&self, start: Coord) -> Location {
        Location {
            start,
            end: self.get_coord(),
        }
    }

    pub fn position_from(&self, start: (BytePos, Coord)) -> Position {
        let span = Span(start.0, self.get_pos());
        let location = Location {
            start: start.1,
            end: self.get_coord(),
        };
        Position::new(span, location)
    }

    /// Advances the underlying iterator until a non-whitespace character is
    /// encountered. Returns a span of byte positions corresponding to the
    /// number of bytes consumed.
    #[inline]
    pub fn eat_whitespace(&mut self) -> Position {
        let start_pos = self.get_pos();
        let start_loc = self.get_coord();
        while matches!(self.peek(), Some(c) if c.is_whitespace()) {
            self.bump();
        }
        Position::new(
            Span(start_pos, self.get_pos()),
            Location {
                start: start_loc,
                end: self.get_coord(),
            },
        )
    }

    /// Consumes characters until encountering a whitespace. For use when
    /// skipping the rest of a potential lexeme during a lexing error.
    #[inline]
    pub fn eat_until_whitespace(&mut self) -> Position {
        self.eat_while(|c| !c.is_whitespace())
    }

    /// Advance the underlying iterator as long as the given character
    /// predicate holds true.
    ///
    /// Note that this method allows the provided closure to implement `FnMut`,
    /// indicating state may not necessarily be unaffected by the closure.
    ///
    /// To get the same functionality but that accepts any type that implements
    /// `Character`, use `bump_while` or the `Iterator` method `next_while`
    /// generated by `Source` `Iterator` implementation.
    pub fn eat_while<F>(&mut self, mut f: F) -> Position
    where
        F: FnMut(char) -> bool,
    {
        let start_pos = self.get_pos();
        let start_loc = self.get_coord();
        while matches!(self.peek(), Some(c) if f(*c)) {
            self.bump();
        }
        Position::new(self.span_from(start_pos), self.location_from(start_loc))
    }

    /// Identifies whether a given character matches that of the character
    /// reference returned by peeking. This will *always* return false if no
    /// more characters are left to be consumed.
    pub fn on_char(&mut self, c: impl Character) -> bool {
        matches!(self.peek(), Some(ch) if c.cmp_char(*ch))
    }

    pub fn eat_while_on(&mut self, c: impl Character) -> Position {
        self.eat_while(|ch| c.cmp_char(ch))
    }

    /// Identifies whether the character returned by `peek` satisfies a given
    /// predicate.
    pub fn test_char<F>(&mut self, f: F) -> bool
    where
        F: Fn(&char) -> bool,
    {
        matches!(self.peek().map(f), Some(true))
    }
}

pub trait Character {
    fn cmp_char(&self, c: char) -> bool;
    fn cmp_str(&self, s: &str) -> bool;
    fn cmp_byte(&self, b: u8) -> bool {
        self.cmp_char(b as char)
    }
    fn cmp_scalar(&self, cp: u32) -> bool {
        std::char::from_u32(cp)
            .map(|c| self.cmp_char(c))
            .unwrap_or_else(|| false)
    }
    fn cmp_utf8(&self, bs: [u8; 4]) -> bool {
        std::str::from_utf8(&bs[..])
            .map(|s| self.cmp_str(s))
            .unwrap_or_else(|_| false)
    }
}

impl Character for char {
    #[inline]
    fn cmp_char(&self, c: char) -> bool {
        *self == c
    }

    #[inline]
    fn cmp_str(&self, s: &str) -> bool {
        let mut chars = s.chars();
        match chars.next() {
            Some(c) if *self == c => chars.next().is_none(),
            _ => false,
        }
    }
}

impl<F> Character for F
where
    F: Fn(char) -> bool,
{
    #[inline]
    fn cmp_char(&self, c: char) -> bool {
        self(c)
    }

    #[inline]
    fn cmp_str(&self, s: &str) -> bool {
        let mut chars = s.chars();
        match chars.next() {
            Some(c) if self(c) => chars.next().is_none(),
            _ => false,
        }
    }
}

impl Character for [char] {
    fn cmp_char(&self, c: char) -> bool {
        for ch in self {
            if *ch == c {
                return true;
            }
        }
        false
    }

    fn cmp_str(&self, s: &str) -> bool {
        self.iter().any(|c| c.cmp_str(s))
    }
}

impl Character for &[char] {
    fn cmp_char(&self, c: char) -> bool {
        self.iter().any(|ch| *ch == c)
    }

    fn cmp_str(&self, s: &str) -> bool {
        self.iter().any(|c| c.cmp_str(s))
    }
}

impl Character for Option<&char> {
    fn cmp_char(&self, c: char) -> bool {
        matches!(self, Some(ch) if **ch == c)
    }

    fn cmp_str(&self, s: &str) -> bool {
        matches!(self, Some(c) if c.cmp_str(s))
    }
}

impl Character for &[u8] {
    fn cmp_char(&self, c: char) -> bool {
        self.iter().any(|b| *b == c as u8)
    }

    fn cmp_str(&self, s: &str) -> bool {
        matches!(std::str::from_utf8(self), Ok(t) if s == t)
    }
}

impl Character for &str {
    fn cmp_char(&self, c: char) -> bool {
        matches!(self.chars().next(), Some(cc) if cc == c)
    }

    fn cmp_str(&self, s: &str) -> bool {
        *self == s
    }
}

impl<'t> std::ops::Index<Span> for Source<'t> {
    type Output = str;

    fn index(&self, Span(a, b): Span) -> &Self::Output {
        let len = self.src.len();
        let start = a.as_usize();
        let end = b.as_usize();
        debug_assert!(start <= len && end <= len);
        match (start, end) {
            (start, end) if start == end => "",
            // allow for inverted spans??
            _ => &self.src[if start > end { end..start } else { start..end }],
        }
    }
}

impl<'t> From<Source<'t>> for String {
    fn from(src: Source<'t>) -> Self {
        src.src.to_string()
    }
}

/// Primarily used to toggle how certain identifiers are lexed, allowing certain
/// "identifiers" to be lexed differently based on upstream-provided contexts.
///
/// The `Default` context corresponds to the majority of the context throughout
/// the program; identifiers are first checked against the set of all `Keyword`s
/// before being categorized as an `Upper` or `Lower` identifier (though this in
/// particular only applies for lower, since no keywords begin with an uppercase
/// letter).
///
/// The `Meta` context is used for attributes and pragmas. While in the `Meta`
/// state, identifiers may be further classified against the set of `Lint` and
/// `Attr` keywords. For example, the string `fixity` gets special treatment
/// when encountered within an attribute e.g., `#[fixity 3L]` (and lexed as a
/// `Pragma`), but is otherwise treated as an identifier when not in the `Meta`
/// scope.
///
/// TBD: The `Macro` context is (to be) used within macro declarations, which
/// will need a separate set of supporting punctuators.
#[derive(Copy, Clone, Debug, PartialEq, Eq)]
pub enum Mode {
    Default,
    /// Lexing the insides of a pragma, i.e., within the square brackets
    /// that follow a hash and an optional bang, e.g., `#[allow all]`.
    /// The `place` field identifies whether the attribute is placed
    /// before or after the item that it annotates. Moreover, the
    /// first token seen after the left bracket `[` in an attribute
    /// forms the *pragma* label and affect the semantic meaning of
    /// the attribute, while the following tokens leading up to the
    /// closing right bracket `]` form the arguments. Whether the
    /// label of an attribute has been seen affects the behavior of
    /// the lexer, with a number of builtin attributes being scanned
    /// for when the `attr_seen` field is `false`.
    Meta {
        place: Placement,
        attr_seen: bool,
    },
    Macro,
}

wy_common::variant_preds! { Mode
    | is_default => Default
    | is_meta => Meta { .. }
    | is_meta_before => Meta { place: Placement::Before, .. }
    | is_meta_after => Meta { place: Placement::After, .. }
    | is_macro => Macro
}

impl Mode {
    /// Returns the value of the `attr_seen` field as an optional
    /// value if the variant is a `Meta` variant, otherwise returns
    /// `None`.
    pub fn attr_witness(&self) -> Option<bool> {
        if let Self::Meta { attr_seen, .. } = self {
            Some(*attr_seen)
        } else {
            None
        }
    }
}

impl Default for Mode {
    fn default() -> Self {
        Self::Default
    }
}

/// An iterator that produces `Token`s for a given string slice and
/// functions as an interface between source text and parsing.
/// Comments are lexed but stored internally and don't produce any tokens.
///
/// Note that the `Lexer` does not record file-related information but
/// *does* track positional information (such as the current byte position
/// (and "layout" related informations such as line an column numbers)
/// within the source text stream). Therefore it follows that each separate
/// source *file* require a new instance of the `Lexer`.
///
/// The `Lexer` may either be directly composed with another iterator,
/// allowing for functionality within a *single* pass. However, as the
/// `Lexer` implements `Iterator`, it is possible to use it as a
/// `Peekable<Lexer>>` for lookahead. Additionally, multiple passes could
/// also be executed by taking advantage of the free methods provided by
/// the `Iterator` trait such as `by_ref` and a pre-processing pass may be
/// implemented by first allocating a vector of `Token`'s using the
/// `<Vec<_> as Iterator>::collect` method.
#[derive(Clone, Debug)]
pub struct Lexer<'t> {
    pub(crate) coords: Vec<Coord>,
    pub(crate) stack: Vec<Token>,
    pub(crate) source: Source<'t>,
    pub comments: Vec<Comment>,
    pub current: Option<Token>,
    pub mode: Mode,
    pub shebang: Option<Span>,
    pub prev_pos: BytePos,
    // nextpos: Option<BytePos>
}

impl<'t> WithLoc for Lexer<'t> {
    fn get_coord(&self) -> Coord {
        if let Some(coord) = self.coords.last() {
            *coord
        } else {
            self.source.get_coord()
        }
    }
}

impl<'t> WithSpan for Lexer<'t> {
    fn get_pos(&self) -> BytePos {
        if self.current.is_some() || !self.stack.is_empty() {
            self.prev_pos
        } else {
            // if let Some(ref tok) = self.current {
            //     // since we've already got the next token in our `current` field, should we return the beginning or end of that token?
            //     tok.span.start()
            // } else if !self.stack.is_empty() {
            //     self.stack[self.stack.len() - 1].span.start()
            // } else {
            self.source.get_pos()
        }
    }
}

impl<'t> Lexer<'t> {
    pub fn new(src: &'t str) -> Self {
        let mut this = Self {
            coords: Vec::new(),
            stack: Vec::new(),
            source: Source::new(src),
            comments: Vec::new(),
            current: None,
            mode: Mode::Default,
            shebang: None,
            prev_pos: BytePos::ZERO,
        };
        this.read_shebang();
        this
    }

    /// Returns the `BytePos` that existed prior to the `BytePos` held
    /// by the next token.
    ///
    /// Suppose we are in the beginning of lexing the following:
    /// ```text
    /// "foo bar baz"
    ///  ^              <- curr pos AND prev_pos
    ///     ^           <-
    /// ```
    pub fn prev_pos(&self) -> BytePos {
        self.prev_pos
    }

    /// Returns the current `BytePos` of the underlying character stream.
    pub fn curr_pos(&self) -> BytePos {
        self.source.get_pos()
    }

    /// Returns the `BytePos` of token returned by calling `peek`.
    pub fn next_pos(&self) -> BytePos {
        if let Some(tok) = self.current.as_ref() {
            tok.span.end()
        } else if self.stack.len() > 0 {
            self.stack[self.stack.len() - 1].span.end()
        } else {
            self.clone().token().span.start()
        }
    }

    pub fn span_from(&self, start: BytePos) -> Span {
        Span(start, self.get_pos())
    }

    pub fn loc_from(&self, start: Coord) -> Location {
        Location {
            start,
            end: self.get_coord(),
        }
    }

    // reason = "need to mutably borrow `self.current` if `None`"
    #[allow(clippy::match_as_ref)]
    pub fn peek(&mut self) -> Option<&Token> {
        match self.current {
            Some(ref t) => Some(t),
            None => {
                if !self.stack.is_empty() {
                    Some(&self.stack[0])
                } else {
                    // self.prev_pos = self.source.get_pos();
                    let token = self.token();
                    self.current.replace(token);
                    self.current.as_ref()
                }
            }
        }
    }

    pub fn bump(&mut self) -> Token {
        match self.current.take() {
            Some(token) => token,
            None => {
                if let Some(tok) = self.stack.pop() {
                    tok
                } else {
                    self.eof_token()
                }
            }
        }
    }

    pub fn eof_token(&self) -> Token {
        let pos = self.source.end_pos();
        Token {
            lexeme: Lexeme::Eof,
            span: Span(pos, pos),
        }
    }

    pub fn is_done(&mut self) -> bool {
        matches!(
            &self.current,
            Some(Token {
                lexeme: Lexeme::Eof,
                ..
            })
        ) || self.stack.is_empty() && (self.source.is_done())
    }

    pub(crate) fn span_symbol(&self, span: Span) -> Symbol {
        Symbol::intern(&self.source[span])
    }

    pub fn on_char(&mut self, ch: impl Character) -> bool {
        self.source.on_char(ch)
    }

    pub fn get_mode(&self) -> &Mode {
        &self.mode
    }

    /// Updates the internal `Mode`. Note that every `Mode` toggle
    /// resets the `attr_seen` of a `Meta` mode to `false`.
    pub fn set_meta_mode(&mut self, placement: Placement) -> &mut Self {
        if self.mode.is_default() {
            self.mode = Mode::Meta {
                place: placement,
                attr_seen: false,
            };
        }
        self
    }

    /// Resets the lexer's `Mode` to `Mode::Default`, modifying how the
    /// lexer scans identifiers.
    pub fn reset_mode(&mut self) -> &mut Self {
        self.mode = Mode::default();
        self
    }

    /// Called immediately upon creation for a new file only and
    /// stores the span inside the lexer corresponding to  
    /// `#!/path/to/compiler` found on the first line of the
    /// text.
    ///
    // Should there be two spans? Moreover, should this be done/stored
    // the lexer or the underlying source stream?
    fn read_shebang(&mut self) {
        #![allow(unused)]
        if self.get_row().is_one() && self.get_col().is_zero() {
            if self.source.src.starts_with("#!/") {
                self.shebang = Some(self.source.eat_while(|c| c != '\n').span())
            }
        }
    }

    pub fn get_shebang_span(&self) -> Option<Span> {
        self.shebang
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_positions() {
        let text = "foo bar baz";
        let mut lexer = Lexer::new(text);
        let posns = |lex: &mut Lexer| (lex.prev_pos(), lex.curr_pos(), lex.next_pos());
        assert_eq!(
            posns(&mut lexer),
            (BytePos::new(0), BytePos::new(0), BytePos::new(0))
        );
        lexer.next();
        assert_eq!(
            posns(&mut lexer),
            (BytePos::new(0), BytePos::new(3), BytePos::new(4))
        );
        lexer.next();
        assert_eq!(
            posns(&mut lexer),
            (BytePos::new(3), BytePos::new(7), BytePos::new(8))
        );
    }

    #[test]
    fn test_stream() {
        use wy_span::*;

        let text = "this \na text-test";
        let mut source = Source::new(text);
        let first = source.bump();
        assert_eq!(first, Some('t'));
        let (span, loc) = source.eat_until_whitespace().parts();
        let one = BytePos::ONE;
        assert_eq!(span, Span(one, one + "his"));
        assert_eq!(
            loc,
            Location {
                start: Coord {
                    row: Row::new(1),
                    col: Col::new(1)
                },
                end: Coord {
                    row: Row::new(1),
                    col: Col::new(4)
                }
            }
        );
        assert_eq!(source.peek(), Some(&' '));
        assert_eq!(source.bump(), Some(' '));
        assert_eq!(source.bump(), Some('\n'));
        assert_eq!(source.get_row(), Row::new(2));
        source.eat_while_on(|c: char| c.is_whitespace() || c == 'a');
        assert_eq!(source.bump(), Some('t'));
        let (span, _) = source.eat_until_whitespace().parts();
        assert_eq!(source.bump(), None);
        assert!(source.is_done());
        assert_eq!(&source[span], "ext-test")
    }
}
